{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza    \n",
    "stanza.download('en') # download English model\n",
    "nlp = stanza.Pipeline('en') # initialize English neural pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('../datasets/2018-EI-oc-En-fear-dev.txt', sep=\"\\t\", header=None, skiprows=1)\n",
    "\n",
    "'''\n",
    "li = []\n",
    "all_files= {'../datasets/2018-EI-oc-En-joy-dev.txt', '../datasets/2018-EI-oc-En-sadness-dev.txt', '../datasets/2018-EI-oc-En-anger-dev.txt', '../datasets/2018-EI-oc-En-fear-dev.txt'}\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", header=None, skiprows=1)\n",
    "    li.append(df)\n",
    "\n",
    "dataset = pd.concat(li, axis=0, ignore_index=True)\n",
    "'''\n",
    "dataset.columns = ['date', 'text', 'emotion', 'level']\n",
    "dataset= dataset.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ng 50yr mark awhile ago–I know #horrific damage #planet occur 'natural' #death.\", 'Africa unique tremendous problem war, overpopulation, starvation tribalism make moving Africa forward hard.', '@user', '@user', 'Something #awestruck today laughing non subtitle korean variety show...', '@user', '@user', 'Wtf shawty as :face_with_steam_from_nose:', '@user', \"There's nothing interesting besides retweet follow #annoyed :persevering_face::persevering_face:\", 'I woke still hardly believing happened last night :anxious_face_with_sweat:', 'Hey @user', \"Can't believe Zain starting secondary year :crying_face:\", '@user', 'I literally love Paul much #BB19 #pissed :face_with_tears_of_joy:', '#World know difference #drunk #sober? One word. #Coherence.', 'This people like Saleem Sheikh humanity win terrorism n hatred #AmarnathYatraAttacked', 'Just watching #Phoenix video first time. Holy fuck, guy seriously deranged, unhinged. Why everyone #terrified?', 'How come quiet well behaved cat dog ride plane tiny bag screaming small human roam free? #outrage #teampet', 'When Duane Allman died, I learned appreciate Stevie Ray Vaughan. True story. #blues #legends', 'Something #awestruck today laughing non subtitle korean variety show...', '@user', 'How feel @user', '@user', '@user', 'If @user', 'Wrapped In This Burrito, Gotta Sweat This All Out :anxious_face_with_sweat:', \"I actually watch drug destroy entire family :crying_face:Mother's skid row. Oldest daughter lost child. Father estranged. #horrific\", 'I mean, I wanted goat faint... I wanted see goat faint. #eclipse', 'Worst dreams. :sad_but_relieved_face:', '@user', '@user', \"#depressed Today bitter sweet watching kid go back school made really miss babies. I'm broke #backtoschool2017\", \"already 3 Nico URs really need smile UR ;; i'm confused\", '@user', '@user', 'Hey @user', '@user', '@user', 'Wow! Today, totally seeing alot #mean #people #world! Turn around #start cultivating #kindness! #SuccessTRAIN #warrior', '@user', '#IfOnlyPeopleWould exist. #humanity #life #ignorance #nature #mothernature #sad #disappointment #smh #personal #opinion #views #animals', '#dmme #kikme #sext #horny #ass #bbw #naughty #pussy #kik #nudes girl :weary_face: horny #snap jacobgigs', 'I want diamond bright future', 'If going nurse, learn nice patient person, Jesus :upside-down_face:', \"That absolutely two worst National Anthem singer I've ever heard, screwed word #awful\", '@user', '@user', 'My @user', 'It’s lack #faith make #people #afraid #meeting #challenges …\\\\n\\\\n#MuhammadAli', 'Everything I order online come looking like piece shit :face_with_steam_from_nose:', 'Had frustration dream left utterly f**king furious. Plus side: angry sleep, wrote 1500 words. Minus side: still raging!', '@user', 'Please stop ruining depressing meme positivity optimism', '@user', '@user', 'Imagine many ksones cry right getting ticket :loudly_crying_face: Meanwhile, isones dont even get chance go war ticket :loudly_crying_face:', 'Threaten leave girl shaking wet spot ....', 'I like itos manga end bleak hopeless endings, way make look like protagonist lost', '@user', '@user', '@user', '#ContentwiththeLordsPortion:Even time scarcity,”Yet I #rejoice #LORD, I #joy God #salvation.” #Hab 3:18', 'Freakin a...I deleted half episode BIP accident #bachelorinparadise', '@user', '@user', 'Taking time busy catch #great #American #eclipse! It really incredible see even partial view! How view?', \"462 appearance PL 200 goals!! 2.31 game per goal. That's nearly goal every 2 game #crap :face_with_tears_of_joy::face_with_tears_of_joy: :face_with_rolling_eyes::face_with_rolling_eyes::thinking_face::thinking_face: #Rooney\", \"Baby, I'm dancing dark\", 'kid street msn something play instead enjoying outside #bitter #shush', '@user', '@user', \"A loss ain't loss lesson #smile\", \"I'm back Twitter! #madden #madden18 #maddenmobile #ea #nfl #espn #packers\", '@user', '@user', 'Are u sad upset?', 'To #Wyoming: beautiful state road signs, lack thereof, terrible. #lost', 'Remember, everything #lost, gained something else. Without #dark, would never see #stars.', '@user', '@user', \"Baby, I'm dancing dark\", 'Chyna didnt respond rob cu knew damn well plottin. But knew hurt deeply revenge porn', \"Don't fucking tag picture 'family first' cut 5 year ago. You're one me.\", 'Just paid arsehole couple New Found Glory ticket gonna GREAT start birthday weekend :oncoming_fist:', \"Every #DIVA need Period Panteez 2 B X-TRA Confident &amp; Secure! Don't wait 2 UR #period ! #thetalk #fallfashion #instyle\", \"I need study celebrities' birthday bc heart almost stopped I saw Harrison Ford trending... :hushed_face: #relieved\", '@user', 'Listen ... golden brown giving life ... hell foot get dark :downcast_face_with_sweat:', 'A #teacher attempting teach without #inspiring #pupil #desire learn hammering cold iron. #HoraceMann', '@user', 'Being deeply loved someone give strength, loving someone deeply give courage. Lao Tzu #wedding #happy #love', 'I shy first.It usually take minute ass jaw people hanging act according:woman_shrugging_medium_skin_tone:', '@user', \"Been work even 4 hour I've thrown boiling tea everywhere, smashed mug, smashed milk jug sliced finger open:neutral_face:\", 'Time bed real bed four night camping. #bliss', \"'to fill campaign bank account ten million dollars'..trump 2020 campaign start #sad #bad\", 'love dark gurl wit da juicy booty', '@user', \"Beware wrath angry, frustrated, #agile grandma network. :old_woman_medium-light_skin_tone::pouting_face: I'm sayin'. #objectlesson\", 'Be gracious O God...for soul take #refuge You; shadow Your wing I take #refuge... psalm 57:1 #hope #jesus #joy', 'Happy played tgt team once. Thought would another chance sadly no. Rest In Peace dear friend. :(', 'wanna sober u', \"Still #devastated #sad #Tariq's #TariqLive channel #ProfessorBlackTruth well. #YouTubeFAIL #EpicFAIL! #TariqNasheed :crying_face:\", 'Thanks recent follow @user', 'Imagine many ksones cry right getting ticket :loudly_crying_face: Meanwhile, isones dont even get chance go war ticket :loudly_crying_face:', 'Listening refugee children, barely decade old, describe horrific act forced commit terrifying. #DatelineSBS', 'Difficulties, bracing mind overcome them, assist cheerfulness, exercise assist digestion.\\\\nChristian Nestell Bovee #quotes', 'The best thing cooking egg even original idea work, still got scrambled eggs! #optimism', '@user', '@user', \"smiling we're close tear\", '@user', '#AmericasGotTalent live show many technical fault #disheartening', '#ThingsIveLearned The wise #shepherd never trust flock #smiling wolf. #TeamFollowBack #fact #wisewords', 'When know go next.. life..:thinking_face: #lost', '@user', 'Wow! Today, totally seeing alot #mean #people #world! Turn around #start cultivating #kindness! #SuccessTRAIN #warrior', '@user', '@user', '@user', \"Desi feminist must hardest. Imagine controlling rage due dance wedding 'Mai Baarish Kar du Paise ki'\", 'Brighten gloomy day @user', \"Just received fantastic news next 9 bed 'Sui Generis' HMO full planning permission. Build start 01 September. #excited\", 'Yes @user', \"There's still sadness hatred pero feel better yesterday.\", '@user', 'Why FUCK saw Game Thrones spoiler snapchat? SOME OF US HAVENT SAW IT YET :middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone: #arsehole', '@user', '@user', \"I'm kind tired everything #summer #heat #bicycle #videogames #bookwriting #nothavingacomputer\", '@user', \"'we need something. something must done!!!!!'\\\\n\\\\nyour anxiety amusing. nothing done. despair.\", 'So I buy whole new computer', 'That eclipse Angelic :folded_hands_dark_skin_tone: #blessing', 'Nigga write talking bout I dreamt you, cool I hope I haunting nightmare', '@user', '@user', \"Went bed 1:30, fell asleep after, niece started cry 4. I'm dying... :anguished_face:\", \"i've 1 1/3 class today already\", 'Totally regret signing @user', 'A programmer’s wisdom understanding difference getting program run runnable program. #puppy', 'I want digital art bad, dad let use iPad till exam :face_with_tears_of_joy:', \"I've got builder office I game make. Perhaps ill start sketching next game... #gamedev #indiedev\", '@user', '@user', '@user', '@user', '@user', \"You certain #arrogance, I think that's fine, never lose #respect others.\", 'Leviticus 19:14\\\\nYou shall curse #deaf put stumbling #block #blind, shall #fear #God: I [1/2]', 'The moon tonight :face_with_open_mouth: #beautiful', '@user', 'O, melancholy Catacombs quickly wandered Rue Morgue, Madman!', \"Too much caffeine, I'm dyyyying. #jitters #shakes #paranoia #heartbeat1000 :hot_beverage::broken_heart:\", 'Hmm...looks like one @user', 'When enough @user', 'I shy first.It usually take minute ass jaw people hanging act according:woman_shrugging_medium_skin_tone:', '@user', 'Never heard #CaraCaraOranges today. Very #tasty! I highly recommend them! #delicious #GoodForYou #fruits #oranges', '@user', 'Selling nude pic vids kik buy! Dirty_becca69\\\\n\\\\n#kik #kikme #kikusernames #snap #snapchat #findom #nudes #slut #kiktrade #horny', \"dreamed laughing woke sleep first time without sad face , Fair enough see dream '\", 'I’m glad I’m like sad people online gossip bully others entertainment life.', \"Now Ravi Shastri finally appointed head coach, it'll interesting see whether Kohli finally stop throwing tantrums.\", '@user', \"At point I can't tell I follow people politics twitter I need new friends. #wheresthefunny #depressing\", 'Life short jealous, hating, keeping mess, worrying thing concern you.', \"I thinking Fergie's music M.I.L.F seriously, I'm mother someday, I'll M.I.L.F #lmao #Empowerment #adorable\", '4 hours. \\\\n4,189 words.\\\\n1 story.\\\\n#amwriting #horror #publishorperish', 'I really flattered happy hear complement blog! You guy motivates write blog. Thank you! sml :revolving_hearts:', '@user', '@user', '@user', '@user', 'excepted eclipse make believe omniscience force #dissapointed', '@user', '#Rage #disappointment man.... Is life what? Lol', 'Saw first Larsen trap today stressed magpie. I NEVER EVER want see #angry #distressed #wildlife', 'Everything I order online come looking like piece shit :face_with_steam_from_nose:', \"Someone's nicked lunch fridge work!! Roast dinner well! #fuming\", '@user', '@user', '@user', \"How sick must someone wish 'punish' someone friend? #insecure #lonely #miserable #vengeful #RHOC\", 'Do presume richness poorness bring happiness - Santosh Kalwar #quote #mentalhealth #psychology #depression #anxiety', '@user', '@user', 'Kid camp said inner thigh looked like slinky:OK_hand::rolling_on_the_floor_laughing: buddy stretch marks!!!! #SummerCamp #offended', \"#LouiseLinton - hater gonna hate keep your#fabulous self they'll keep #miserable\", \"'What smiling like that'\\\\n'Dominos sent coupon' :grimacing_face:\", 'Everytime I think life getting better never come #sadly', 'Why FUCK saw Game Thrones spoiler snapchat? SOME OF US HAVENT SAW IT YET :middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone::middle_finger_light_skin_tone: #arsehole', \"#wtf #wonderful idea \\\\nyou've bought tweet like that's pretty pointless Me #bye #bye #Twat\", '@user', '@user', '@user', 'understand ppl save wasp , next chance lil dude get gnna sting ur grandma', 'Hearing Song Phone glued ear like singer spoke me... #mad #mad hahah', '@user', 'Time #burst #burstcoin fork??', 'Look upon mine #affliction &amp; \\u200b\\u200b\\u200b#pain\\u200b; &amp; forgive sins. -Ps 25:18', \"I'm sorry also...fuck #currentfeels #anger #bpd #eupd #borderliner #mentalhealth #anxiety #depression #confused\", '@user', '1/If Church attacked fury, inside, mean Church exactly need belong to!', '@user', '+ cant get tell offend', 'I like #glow #dark #fidgetspinner. Not glow dark neither. It feel lighter smoother others', '@user', 'maybe joey ignored tinder posted social medium trip Hawaii :frowning_face: #bitter', 'realize may worry gone long! fear not, made new life sewers,', '@user', '@user', '@user', \"The part roof bar (driver's side) stolen Grand Vitara cars. Let known. This really #disheartening #brunei\", '#dmme #kikme #sext #horny #ass #bbw #naughty #pussy #kik #nudes girl :weary_face: horny #snap jacobgigs', 'Get feeling @user', 'Jeong su easy get along everybody like intimidated him.. I like him.. reminds seunghoon', '@user', 'I feel intimidated', 'Paul Ehrlich said humanity threat life. Such great news start day. If I could blush I would.', '@user', '@user', 'Yes @user', '@user', 'How shit depressing weather wish I travel world living', 'He charming smile really make smile too. Believe me.', '5 goal 87 appearance last season McKay, Holt Windass! Simply horrific! Get midfield balance sorted team fire!', 'I’m glad I’m like sad people online gossip bully others entertainment life.', 'And #wonderful boy Garden grew wisdom stature favour God men, which, literally, parents.\\\\n#VSS365', 'How shit depressing weather wish I travel world living', '@user', \"' can't even tell u lie I felt like u special, till I realized wassup left, got u feeling dreadful '\", \"It's strange juxtaposition emotions. A sense euphoria sense despair.\", 'Leviticus 19:14\\\\nYou shall curse #deaf put stumbling #block #blind, shall #fear #God: I [1/2]', '@user', '@user', 'friend sad: basically becomes psychiatrist\\\\nmy friend im sad: ok #funny #lol', '@user', 'So disappointed spending £50 outfit meeting boy #noselfcontrol #nervous', 'People always afraid stodgy square would kill rock roll, legitimate threat ever child choruses.', 'An unchallenged present creates complacent future. #TuesdayThought #selfimprovement #success #excitement', 'So happy home Ibiza place thing else mad gaff , need find bird I wanna start romantic thing :face_with_tears_of_joy::face_with_tears_of_joy:', 'anyways apologized &amp; hav rly bad anxiety guy wanted get &amp; start errand &amp; ~uber everywhere~', 'A programmer’s wisdom understanding difference getting program run runnable program. #puppy', 'It could soul-crushing despair, also might marshmallow I breakfast', '#resentment best Beyoncé song #dontdebateme', 'one moron driving oversize tonka truck big flag bed back forth blaring country music. :neutral_face: #disappointment', '@user', 'Government take strong action terrorism #AmarnathTerrorAttack KADI NINDA', 'I’m glad I’m like sad people online gossip bully others entertainment life.', 'Because @user', 'Each every time I log website view Lindsey Vonn pic I #saddened courseness culture.', \"Israel's recent overture towards West Africa seems attracting element suspicion...an unnecessary suspicion though.\", 'Definitely something happening today #SolarEclipse2017 #weird #annoyed', '@user', 'Dannie terrible influence, piercing time:face_with_tears_of_joy::syringe:', 'guess stayed 2am incase someone called never like knew already , me, mistake made', '@user', 'Great...So I got 5am discover Amazon Prime Day deal $30 regular price. :pouting_face:', '@user', '@user', '@user', 'Girls masturbate too,boys cry too!\\\\n#girls # boy #cry #masturbate', 'Caleb nightmare zombies. I dream freedom.......', 'The blackest abyss despair, Alonzo', 'That banished sadness, way I am? #somber', '@user', 'At groovy restaurant. Got cheeseburger fries. I discriminate. Rating; 5/7 #yummy #delicious #politicallycorrect', 'What I heart trembling thought it?\\\\nI really don’t know love', '#RIPBiwott I think Robert oukos soul rejoice rest peace. Call evil man evil good man good man. He evil man', 'Lost appetite past 5 day I swear I already lost 3 pound #depressing #at #least #i #will #be #skinny #for #pride #weekend', 'That moment look back realise #selfish #horrible #judgemental person. #FeelingAshamed', \"Imagine suffering chronic depression told 'you unattractive chip shoulder' #DWP #WRAG #WWW.GOV.UK #Mentalhealth\", '@user', \"Can't drink day u start morning .. Drake get :face_with_tongue:\", \"y'all understand. woman's wrath REAL. :rose::black_heart:\", 'It’s lack #faith make #people #afraid #meeting #challenges …\\\\n\\\\n#MuhammadAli', 'everybody seem sp serious?', 'bonless sirlion tips,mixed veggie browngravy &amp; homemade mashed potato #inthekitchen #latenightmunchies #yummy #getuagirlthatcancook', '@user', \"'we need something. something must done!!!!!'\\\\n\\\\nyour anxiety amusing. nothing done. despair.\", 'everyone know died treaty involvement drawing up, get enormous amount fury', '#Worry never robs tomorrow #sorrow; sap today #strength - A. J. Crown #faith #positive #motivation', 'Jeong su easy get along everybody like intimidated him.. I like him.. reminds seunghoon', \"I click download PC. Message say 'Thank downloading #iTunes \\\\nSo, where's download?! #frustrated\", '@user', \"+++ '#Dearly #beloved, avenge yourselves, rather give place unto #wrath: #written, #Vengeance #mine; I …' #Romans12v19\", 'Just paid arsehole couple New Found Glory ticket gonna GREAT start birthday weekend :oncoming_fist:', 'We opportunity move away gloomy nihilism characterizes reign deeply patriarchal, dominator culture.', 'anxiety pay', 'wow :o included playlist #awesome', \"Is supposed arduous interact people? I'm 'other people' seem struggle.\", '#redvelvet #wendy #seulgi #irene #yeri #joy \\\\n1. Which member drink sparkling water ?', '@user', '@user', 'Russia story infuriate Trump today. Media otherwise would giving tongue bath fall ISIS Mosul + al-Baghdadi death.', '@user', 'The pessimist complains wind; optimist expects change; realist adjusts sails.', 'nomore drinking :relieved_face::face_with_tears_of_joy: #serious', '@user', \"What's worse feeling discouraged? Not finding emoji feeling discouraged\", 'Okay @user', '@user', \"Like I might've set top car &amp; so, shit long gone :loudly_crying_face:\", 'Yes @user', '@user', 'I mean, I wanted goat faint... I wanted see goat faint. #eclipse', '@user', \"+++ '#Dearly #beloved, avenge yourselves, rather give place unto #wrath: #written, #Vengeance #mine; I …' #Romans12v19\", '#AmericasGotTalent live show many technical fault #disheartening', '@user', 'I’m glad I’m like sad people online gossip bully others entertainment life.', 'Shit getting irritated :angry_face:', 'Literally hanging thread need taylor ray tonight loving bad dog suck #taylorrayholbrook #hurting @user', 'Russia story infuriate Trump today. Media otherwise would giving tongue bath fall ISIS Mosul + al-Baghdadi death.', '#Twitter day massive critical debate people like #annoying #depressing #dull :expressionless_face:', \"'When mind denied emotional sting losing never figure win.' -Jonah Lehrer\", 'Good time never fade away #smile', 'understand ppl save wasp , next chance lil dude get gnna sting ur grandma', 'wake somewhere else...you know #arsehole pressed button ;)', '@user', 'Last Sunday YouTube glitch making lose 20 sub heartbreaking channel size! Nearly 1K though #1Ksubs #youtube soon :grinning_face:', '#AmericasGotTalent live show many technical fault #disheartening', 'She mad sus hung :face_with_tears_of_joy:', '@user', \"Can't handle rude people. Doesn't matter job do, consultant not, treat people would like treated :pouting_face: #disapointed\", '@user', \"'your marker teacher'.i looked n burst laughing swear kid never take seriously :woman_facepalming_light_skin_tone:\", 'Literally hanging thread need taylor ray tonight loving bad dog suck #taylorrayholbrook #hurting @user', '@user', '@user', 'What miserable as weather :loudly_crying_face: dark gloomy #depressing #weekoff #wheresthesun', \"Is supposed arduous interact people? I'm 'other people' seem struggle.\", \"y'all understand. woman's wrath REAL. :rose::black_heart:\", 'I love seeing @user', 'Brown envelope induce panic. #posttruth', 'Hey @user', '@user', 'My boyfriend whole world :loudly_crying_face:', '@user', 'Africa unique tremendous problem war, overpopulation, starvation tribalism make moving Africa forward hard.', 'Got woken road sweeper I trying sleep', 'Worst dreams. :sad_but_relieved_face:']\n"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "corpus = []\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    tweet = row['text']\n",
    "\n",
    "    #handle users\n",
    "    tweet = re.sub('@.*', '@user', tweet) \n",
    "\n",
    "    \n",
    "    \n",
    "    tweet = tweet.split()\n",
    "    #tweet = nltk.word_tokenize(tweet)\n",
    "\n",
    "    # stemming and stop word removal\n",
    "    tweet = ' '.join([lemmatizer.lemmatize(w) for w in tweet if not w in set(stopwords.words('english'))])\n",
    "    \n",
    "\n",
    "    #tweet = nlp(tweet) # run annotation over a sentence\n",
    "    \n",
    "    \n",
    "    #emojis\n",
    "    tweet = emoji.demojize(tweet)\n",
    "    \n",
    "    corpus.append(tweet)\n",
    "\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 1281)\t0.32158820001784094\n  (0, 1274)\t0.32158820001784094\n  (0, 1066)\t0.32158820001784094\n  (0, 2620)\t0.32158820001784094\n  (0, 2416)\t0.2827980059586843\n  (0, 1364)\t0.32158820001784094\n  (0, 654)\t0.32158820001784094\n  (0, 1312)\t0.3044232657010189\n  (0, 657)\t0.32158820001784094\n  (0, 1901)\t0.32158820001784094\n  (1, 1110)\t0.2105456694613085\n  (1, 2342)\t0.22171309039165765\n  (1, 21)\t0.23866725225620697\n  (1, 2546)\t0.21566188809978248\n  (1, 20)\t0.23866725225620697\n  (1, 1688)\t0.21566188809978248\n  (1, 2289)\t0.2291191634467254\n  (1, 464)\t0.2291191634467254\n  (1, 1175)\t0.2105456694613085\n  (1, 2426)\t0.23866725225620697\n  (1, 22)\t0.2291191634467254\n  (1, 1502)\t0.2105456694613085\n  (1, 1537)\t0.19554440759857436\n  (1, 1067)\t0.23866725225620697\n  (1, 2879)\t0.4582383268934508\n  :\t:\n  (1459, 2795)\t0.4588129914497841\n  (1459, 360)\t0.5290325181166741\n  (1459, 1665)\t0.42279447545993915\n  (1460, 2699)\t1.0\n  (1461, 2625)\t0.275690204712694\n  (1461, 1832)\t0.275690204712694\n  (1461, 2677)\t0.275690204712694\n  (1461, 1988)\t0.26677876419434754\n  (1461, 1648)\t0.26677876419434754\n  (1461, 2623)\t0.26677876419434754\n  (1461, 91)\t0.5066828792665002\n  (1461, 2386)\t0.26677876419434754\n  (1461, 2748)\t0.2433049695410717\n  (1461, 1148)\t0.2433049695410717\n  (1461, 1533)\t0.20250439847704055\n  (1461, 997)\t0.26677876419434754\n  (1462, 2638)\t0.4043140337516117\n  (1462, 2460)\t0.44944149058388416\n  (1462, 2128)\t0.423043620584092\n  (1462, 2820)\t0.44944149058388416\n  (1462, 2298)\t0.3779161637518196\n  (1462, 1093)\t0.3327887069195471\n  (1463, 2164)\t0.5887546534880539\n  (1463, 748)\t0.6254928716015709\n  (1463, 2844)\t0.5119830325037955\n"
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(tfidf_vectorizer_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = CountVectorizer(max_features = 1500)\n",
    "#X = vectorizer.fit_transform(corpus).toarray()\n",
    "X = tfidf_vectorizer_vectors.toarray()\n",
    "y = []\n",
    "for index, row in dataset.iterrows():\n",
    "    '''\n",
    "    if(int(row['level'][0])==3):\n",
    "        y.append(2) \n",
    "    elif(int(row['level'][0])>0):\n",
    "        y.append(1) \n",
    "    else:\n",
    "        y.append(0)\n",
    "    '''\n",
    "    y.append(int(row['level'][0]))\n",
    "y = np.array(y)\n",
    "#print(vectorizer.get_feature_names())\n",
    "#print(type(X[0]), y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"\\nfrom nltk.featstruct import FeatStruct\\n\\nX = []\\ni=0\\n\\nfor index, row in dataset.iterrows():\\n    element= []\\n    element.append(tfidf_vectorizer_vectors[i].toarray())\\n    element.append(np.array([0 if i !=len(row['text']) else 1 for i in range(500)]))\\n    element=np.array(element)\\n    element=element.flatten()\\n    X.append(element)\\n    i+=1\\n    fs1 = FeatStruct(tdidf=tfidf_vectorizer_vectors[i], size=[0 if i !=len(row['text']) else 1 for i in range(500)])\\n    X.append(fs1)\\nX=np.array(X)\\nprint(X.shape)\\n\""
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "'''\n",
    "from nltk.featstruct import FeatStruct\n",
    "\n",
    "X = []\n",
    "i=0\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    element= []\n",
    "    element.append(tfidf_vectorizer_vectors[i].toarray())\n",
    "    element.append(np.array([0 if i !=len(row['text']) else 1 for i in range(500)]))\n",
    "    element=np.array(element)\n",
    "    element=element.flatten()\n",
    "    X.append(element)\n",
    "    i+=1\n",
    "    fs1 = FeatStruct(tdidf=tfidf_vectorizer_vectors[i], size=[0 if i !=len(row['text']) else 1 for i in range(500)])\n",
    "    X.append(fs1)\n",
    "X=np.array(X)\n",
    "print(X.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1171, 2887) (1171,)\n(293, 2887) (293,)\n"
    }
   ],
   "source": [
    "# Split dataset into training and test sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[59 12 11 48]\n [ 9  6 10 35]\n [ 9 11 13 28]\n [ 9  6 10 17]]\nAccuracy:  0.3242320819112628\nPrecision:  0.42004304802071496\nRecall:  0.3242320819112628\nF1:  0.34847176720717227\n"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[118   6   6   0]\n [ 51   2   5   2]\n [ 49   1   9   2]\n [ 32   2   7   1]]\nAccuracy:  0.44368600682593856\nPrecision:  0.34471817147585065\nRecall:  0.44368600682593856\nF1:  0.3357734831577814\n"
    }
   ],
   "source": [
    "# SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[121   5   4   0]\n [ 52   2   4   2]\n [ 51   1   8   1]\n [ 34   2   6   0]]\nAccuracy:  0.447098976109215\nPrecision:  0.32474679327604167\nRecall:  0.447098976109215\nF1:  0.3285668320817538\n"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[64  8 57  1]\n [17  2 37  4]\n [15  1 40  5]\n [ 4  2 34  2]]\nAccuracy:  0.36860068259385664\nPrecision:  0.38892347697808444\nRecall:  0.36860068259385664\nF1:  0.34149028020159256\n"
    }
   ],
   "source": [
    "# Perceptron\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "classifier = Perceptron() \n",
    "classifier.fit(X_train, y_train) \n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred)) \n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred)) \n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted')) \n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted')) \n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[111  12   6   1]\n [ 40   7   8   5]\n [ 43   6   8   4]\n [ 19   3  14   6]]\nAccuracy:  0.45051194539249145\nPrecision:  0.3824301516341126\nRecall:  0.45051194539249145\nF1:  0.3837437101670087\n"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[118   6   6   0]\n [ 49   2   6   3]\n [ 44   5   7   5]\n [ 29   3   9   1]]\nAccuracy:  0.43686006825938567\nPrecision:  0.3117178612059158\nRecall:  0.43686006825938567\nF1:  0.3321480481135425\n"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall: ', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('F1: ', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'rev' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3e7b62aa217b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter tweet: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^a-zA-Z]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rev' is not defined"
     ]
    }
   ],
   "source": [
    "# Simple test\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "tweet = input(\"Enter tweet: \")\n",
    "tweet = re.sub('[^a-zA-Z]', ' ', rev).split()\n",
    "tweet = ' '.join([ps.stem(w) for w in tweet])\n",
    "X = vectorizer.transform([tweet]).toarray()\n",
    "\n",
    "print(X.shape)\n",
    "print(X)\n",
    "\n",
    "print(\"Sentiment level: \", classifier.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('python37': venv)",
   "language": "python",
   "name": "python36964bitpython37venvb1b630360d0f4ea08bfe0f6fcf349387"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}